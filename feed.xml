<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="srgonao.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="srgonao.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-01-02T22:48:00+00:00</updated><id>srgonao.github.io/feed.xml</id><title type="html">Gonçalo Paulo</title><subtitle>My research blog. </subtitle><entry><title type="html">Test Blog Post</title><link href="srgonao.github.io/blog/test-blog/" rel="alternate" type="text/html" title="Test Blog Post"/><published>2024-12-18T00:00:00+00:00</published><updated>2024-12-18T00:00:00+00:00</updated><id>srgonao.github.io/blog/test-blog</id><content type="html" xml:base="srgonao.github.io/blog/test-blog/"><![CDATA[<p>This is a test blog post to verify the blog section is working.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[This is a test blog post to verify the blog section is working.]]></summary></entry><entry><title type="html">SAEs trained on the same data don’t learn the same features | EleutherAI Blog</title><link href="srgonao.github.io/blog/saes-trained-on-the-same-data-dont-learn-the-same-features-eleutherai-blog/" rel="alternate" type="text/html" title="SAEs trained on the same data don’t learn the same features | EleutherAI Blog"/><published>2024-12-12T00:00:00+00:00</published><updated>2024-12-12T00:00:00+00:00</updated><id>srgonao.github.io/blog/saes-trained-on-the-same-data-dont-learn-the-same-features--eleutherai-blog</id><content type="html" xml:base="srgonao.github.io/blog/saes-trained-on-the-same-data-dont-learn-the-same-features-eleutherai-blog/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[In this post, we show that when two TopK SAEs are trained on the same data, with the same batch order but with different random initializations, there are many latents in the first SAE that don't have a close counterpart in the second, and vice versa. Indeed, when training only about 53% of the features are shared Furthermore, many of these unshared latents are interpretable. We find that narrower SAEs have a higher feature overlap across random seeds, and as the size of the SAE increases, the overlap decreases.]]></summary></entry><entry><title type="html">Partially rewriting an LLM in natural language | EleutherAI Blog</title><link href="srgonao.github.io/blog/partially-rewriting-an-llm-in-natural-language-eleutherai-blog/" rel="alternate" type="text/html" title="Partially rewriting an LLM in natural language | EleutherAI Blog"/><published>2024-11-10T00:00:00+00:00</published><updated>2024-11-10T00:00:00+00:00</updated><id>srgonao.github.io/blog/partially-rewriting-an-llm-in-natural-language--eleutherai-blog</id><content type="html" xml:base="srgonao.github.io/blog/partially-rewriting-an-llm-in-natural-language-eleutherai-blog/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Using interpretations of SAE latents to simulate activations.]]></summary></entry><entry><title type="html">Open Source Automated Interpretability for Sparse Autoencoder Features | EleutherAI Blog</title><link href="srgonao.github.io/blog/open-source-automated-interpretability-for-sparse-autoencoder-features-eleutherai-blog/" rel="alternate" type="text/html" title="Open Source Automated Interpretability for Sparse Autoencoder Features | EleutherAI Blog"/><published>2024-07-30T00:00:00+00:00</published><updated>2024-07-30T00:00:00+00:00</updated><id>srgonao.github.io/blog/open-source-automated-interpretability-for-sparse-autoencoder-features--eleutherai-blog</id><content type="html" xml:base="srgonao.github.io/blog/open-source-automated-interpretability-for-sparse-autoencoder-features-eleutherai-blog/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Building and evaluating an open-source pipeline for auto-interpretability]]></summary></entry></feed>